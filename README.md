## Abstract
*Nowadays memes have become a way in which people express their ideas on social media. These memes can convey various views including offensive ones. Memes can be intended for a personal attack, homophobic abuse, racial abuse, attack on minority etc. The memes are implicit and multi-modal in nature. Here we analyze the meme by categorizing them as offensive or not offensive and this becomes a binary classification problem. We propose a novel offensive meme classification using the transformer-based image encoder, BiLSTM for text with mean pooling as text encoder and a Feed-Forward Network as a classification head. The SwinT + BiLSTM has performed better when compared to the ViT + BiLSTM across all the dimensions. The performance of the models has improved significantly when the contextual embeddings from DistilBert replace the custom embeddings. We have achieved the highest recall of 0.631 by combining outputs of four models using the soft voting technique*

## Model Architecture
<p align="center">
<img  src="https://user-images.githubusercontent.com/46472021/158046394-ba1a62c4-728e-49d9-a761-857da483a3a7.png" width="600" height ="600" />
 </p> 
 
 ## Results
 
 <p align="center">
<img  src="https://user-images.githubusercontent.com/46472021/158046446-4731c81b-3ccc-4ca7-bd50-67111b4fa0e6.png" width="850" height ="300" />
 </p> 
 
<p align="center">
<img  src="https://user-images.githubusercontent.com/46472021/158046482-e662f247-741f-43ed-9d62-9df3927262c0.png" width="850" height ="300" />
 </p> 
 

![image](https://user-images.githubusercontent.com/46472021/158046713-fa399068-f57f-4721-8c15-03b7c4ed78fc.png)
